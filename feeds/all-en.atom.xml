<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog</title><link href="http://ocefpaf.github.io/" rel="alternate"></link><link href="http://ocefpaf.github.io/feeds/all-en.atom.xml" rel="self"></link><id>http://ocefpaf.github.io/</id><updated>2013-07-14T15:15:00Z</updated><entry><title>Plotting AVISO track from their kmz file</title><link href="http://ocefpaf.github.io/plotting.html" rel="alternate"></link><updated>2013-07-14T15:15:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-07-14:plotting.html</id><summary type="html">&lt;p&gt;satellite tracks.&lt;/p&gt;
&lt;p&gt;AVISO &lt;a href="http://www.aviso.oceanobs.com/en/altimetry.html"&gt;Altimetry&lt;/a&gt; is available
in both gridded and track data.  Sometime track data is desirable to augment
hydrographic data due to its higher resolution and/or to avoid the several
assumptions done for the grid interpolation.  If order to find the closest
track near to your area of interest one must check the satellites available.
The AVISO group have a nice kmz compilation with all the satellites tracks
availability in time:&lt;/p&gt;
&lt;p&gt;http://www.aviso.oceanobs.com/en/data/tools/pass-locator.html&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/Keyhole_Markup_Language"&gt;kmz&lt;/a&gt; is just a
compressed kml.  So it is straight forward to unzip it and read its information
with a simple python script.  we will need to import zipfile and a kml parser&lt;/p&gt;
&lt;p&gt;{% notebook AVISO_tracks.ipynb cells[0:1] %}&lt;/p&gt;</summary><category term="AVISO"></category><category term="plotting"></category><category term="SSH"></category></entry><entry><title>Removing spikes from CTD data -- Part 2</title><link href="http://ocefpaf.github.io/spikes_2.html" rel="alternate"></link><updated>2013-07-03T04:03:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-07-03:spikes_2.html</id><summary type="html">&lt;p&gt;CTD data main contain, in general, two different types of spikes:
&lt;em&gt; Bad data from electrical failures.  Usually it manifest in all the measured
  variables (Temperature, Conductivity, Oxygen, etc);
&lt;/em&gt; Salinity spikes due to a wrong temperature value when computing it from
  conductivity.  This effect may be due to a a bad Alignment of the temperature
  and conductivity sensors or poor Cell thermal mass correction.
  For more information check Lueck, R.G., 1990: Thermal Inertia of Conductivity
  Cells: Theory., American Meteorological Society Oct 1990, 741-755.&lt;/p&gt;</summary><category term="CTD"></category><category term="hydrography"></category></entry><entry><title>Removing spikes from CTD data -- Part 1</title><link href="http://ocefpaf.github.io/spikes_1.html" rel="alternate"></link><updated>2013-06-03T04:03:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-06-03:spikes_1.html</id><summary type="html">&lt;p&gt;CTD data main contain, in general, two different types of spikes:
&lt;em&gt; Bad data from electrical failures.  Usually it manifest in all the measured
  variables (Temperature, Conductivity, Oxygen, etc);
&lt;/em&gt; Salinity spikes due to a wrong temperature value when computing it from
  conductivity.  This effect may be due to a a bad Alignment of the temperature
  and conductivity sensors or poor Cell thermal mass correction.
  For more information check Lueck, R.G., 1990: Thermal Inertia of Conductivity
  Cells: Theory., American Meteorological Society Oct 1990, 741-755.&lt;/p&gt;</summary><category term="CTD"></category><category term="hydrography"></category></entry><entry><title>Pandas for CTD data</title><link href="http://ocefpaf.github.io/CTD.html" rel="alternate"></link><updated>2013-05-26T07:19:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-26:CTD.html</id><summary type="html">&lt;p&gt;&lt;a href="http://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; is an amazing python module to deal with
data.  It has tons of features worthwhile learning, but the best of all is how
quick one can explore a data with just a few code lines once you learn the
basics.&lt;/p&gt;
&lt;p&gt;I wrote a small &lt;a href="http://code.google.com/p/python-oceans/source/browse/oceans/ctd/ctd.py#619"&gt;module&lt;/a&gt;
to read CTD (also XBT's EDF and FSI's CTD format) data directly as a pandas
DataFrame.  Here is an example how to use it:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[1:2] %}&lt;/p&gt;
&lt;p&gt;That's it the compressed &lt;a href="http://www.seabird.com/software/SBEDataProcforWindows.htm"&gt;SeaBird&lt;/a&gt; cnv file is loaded
into memory.&lt;/p&gt;
&lt;p&gt;If you have the Rossete file you can load and make a simple bottle summary with just two lines:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[2:3] %}&lt;/p&gt;
&lt;p&gt;Metadata and data flags are easily accessed.&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[3:4] %}&lt;/p&gt;
&lt;p&gt;Cleaning the DataFrame and manipulating the variables inside it is straight
forward:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[4:5] %}&lt;/p&gt;
&lt;p&gt;There are some rudimentary CTD processing steps similar to those found in the
SBE Software:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[6:11] %}&lt;/p&gt;
&lt;p&gt;This also allows for a more customize "derived" step:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[11:12] %}&lt;/p&gt;
&lt;p&gt;Last but not least a handy way for plotting the data:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[12:15] %}&lt;/p&gt;</summary><category term="CTD"></category><category term="pandas"></category></entry><entry><title>Dealing with spiky data</title><link href="http://ocefpaf.github.io/data.html" rel="alternate"></link><updated>2013-05-20T22:58:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-20:data.html</id><summary type="html">&lt;p&gt;The first steps to clean a data-set is to remove outliers (or spikes).  Some
spikes are easy to spot with a simple histogram of the data.  Let's take a look
at a velocity time-series with some bad data.&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[3:4] %}&lt;/p&gt;
&lt;p&gt;Can you see the bins that separate themselves from the rest?  Those are
probably spikes.  It is common practice to use a criteria of labeling the data
$3\times \sigma$ larger than the mean as outliers.  However, some spikes might
be "hidden" within the data limits, or one can remove good data together with
bad data if the data is highly variable (or episodic systems).  For a better
discussion on this topic check out Chapter 2 from Emery and Thomson -- Data
Analysis Methods in Physical Oceanography.&lt;/p&gt;
&lt;p&gt;One solution is a "two(or more)-pass" criteria.  Also, one might wish to
evaluate small chunks of the data separately.  Here is an example:&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[1:2] %}&lt;/p&gt;
&lt;p&gt;The first compute the statistics of the data ($\mu$ and $\sigma$) and marks
(but do not exclude yet) data that deviates more than $n1 \times \sigma$ from
the mean.  The second pass recompute the data statistics but now removing the
data that deviates more than $n2 \times \sigma$ from the mean.&lt;/p&gt;
&lt;p&gt;The code above makes use of &lt;a href="http://stackoverflow.com/questions/4936620/using-strides-for-an-efficient-moving-average-filter" title="NumPy stride tricks"&gt;NumPy stride tricks&lt;/a&gt;
to avoid loops while computing $\mu$ and $\sigma$ for each &lt;strong&gt;block&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[4:5] %}&lt;/p&gt;
&lt;p&gt;The "two-pass" method did well for &lt;em&gt;u&lt;/em&gt; while the $3\times \sigma$ criteria
failed not only to identify all the spikes, but also removed good data from the
time series.  On the other had, the $3\times \sigma$ criteria removed two bad
values from &lt;em&gt;v&lt;/em&gt; while the two pass could one find one.  Still both methods left
behind two small spikes on &lt;em&gt;v&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are probably better ways of doing this.  Also, there are methods that are
more statistically robust and more efficient at catching bad values.  Still,
the message of this post is not actually an algorithm to remove bad data, but:&lt;/p&gt;
&lt;p&gt;"To identify errors, it is necessary to examine all of the data in visual form
and to get a "feel" for the data."  -- directly from Emery and Thomson book.&lt;/p&gt;
&lt;p&gt;In other words, there is no silver bullet!&lt;/p&gt;
&lt;p&gt;http://www.johndcook.com/blog/2013/05/30/there-are-no-outliers/&lt;/p&gt;</summary><category term="plotting"></category><category term="spikes"></category></entry><entry><title>Using Basemap to plot points over a SST figure</title><link href="http://ocefpaf.github.io/mapping.html" rel="alternate"></link><updated>2013-05-13T22:58:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-13:mapping.html</id><summary type="html">&lt;p&gt;Plotting a hydrographic cruise over the latest Sea Surface Temperature image
available can help a lot with the planning and/or interpretation of the cruise
data.&lt;/p&gt;
&lt;p&gt;So first lets define a handy function to generate the such a map:&lt;/p&gt;
&lt;p&gt;{% notebook plotting_over_image.ipynb cells[0:1] %}&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now just download your SST image.&lt;/li&gt;
&lt;li&gt;Crop the image at known lon/lat corners.&lt;/li&gt;
&lt;li&gt;Plot your data!&lt;/li&gt;
&lt;/ul&gt;
&lt;p %="%" cells[1:2]="cells[1:2]" notebook="notebook" plotting_over_image.ipynb="plotting_over_image.ipynb"&gt;Here is the result:&lt;/p&gt;</summary><category term="plotting"></category><category term="basemap"></category><category term="georeference"></category></entry><entry><title>python4oceanographers</title><link href="http://ocefpaf.github.io/first-post.html" rel="alternate"></link><updated>2013-05-06T13:37:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-06:first-post.html</id><summary type="html">&lt;p&gt;I'll &lt;s&gt;try&lt;/s&gt; to write here some code snippets to help analyze, visualize and
explore data in oceans sciences.&lt;/p&gt;
&lt;p&gt;Mostly this is a "notebook" for a future Data Analysis course.&lt;/p&gt;
&lt;p&gt;&lt;font color="red"&gt;This post is just a test!&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Testing a full notebook:&lt;/p&gt;
&lt;p&gt;{% notebook SymPy.ipynb %}&lt;/p&gt;
&lt;p&gt;Now just some cells (from the same notebook):&lt;/p&gt;
&lt;p&gt;{% notebook SymPy.ipynb cells[5:6] %}&lt;/p&gt;
&lt;p&gt;Include code examples:&lt;/p&gt;
&lt;p&gt;{% include_code hello_world.py [Code test] %}&lt;/p&gt;
&lt;p&gt;Seems to work fine!&lt;/p&gt;</summary><category term="test-drive"></category></entry></feed>