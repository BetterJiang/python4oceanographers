<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Pelican Blog</title><link href="http://ocefpaf.github.io/" rel="alternate"></link><link href="http://ocefpaf.github.io/feeds/data-analysis.atom.xml" rel="self"></link><id>http://ocefpaf.github.io/</id><updated>2013-07-03T04:03:00Z</updated><entry><title>Removing spikes from CTD data -- Part 2</title><link href="http://ocefpaf.github.io/spikes_2.html" rel="alternate"></link><updated>2013-07-03T04:03:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-07-03:spikes_2.html</id><summary type="html">&lt;p&gt;CTD data main contain, in general, two different types of spikes:
&lt;em&gt; Bad data from electrical failures.  Usually it manifest in all the measured
  variables (Temperature, Conductivity, Oxygen, etc);
&lt;/em&gt; Salinity spikes due to a wrong temperature value when computing it from
  conductivity.  This effect may be due to a a bad Alignment of the temperature
  and conductivity sensors or poor Cell thermal mass correction.
  For more information check Lueck, R.G., 1990: Thermal Inertia of Conductivity
  Cells: Theory., American Meteorological Society Oct 1990, 741-755.&lt;/p&gt;</summary><category term="CTD"></category><category term="hydrography"></category></entry><entry><title>Removing spikes from CTD data -- Part 1</title><link href="http://ocefpaf.github.io/spikes_1.html" rel="alternate"></link><updated>2013-06-03T04:03:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-06-03:spikes_1.html</id><summary type="html">&lt;p&gt;CTD data main contain, in general, two different types of spikes:
&lt;em&gt; Bad data from electrical failures.  Usually it manifest in all the measured
  variables (Temperature, Conductivity, Oxygen, etc);
&lt;/em&gt; Salinity spikes due to a wrong temperature value when computing it from
  conductivity.  This effect may be due to a a bad Alignment of the temperature
  and conductivity sensors or poor Cell thermal mass correction.
  For more information check Lueck, R.G., 1990: Thermal Inertia of Conductivity
  Cells: Theory., American Meteorological Society Oct 1990, 741-755.&lt;/p&gt;</summary><category term="CTD"></category><category term="hydrography"></category></entry><entry><title>Pandas for CTD data</title><link href="http://ocefpaf.github.io/CTD.html" rel="alternate"></link><updated>2013-05-26T07:19:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-26:CTD.html</id><summary type="html">&lt;p&gt;&lt;a href="http://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; is an amazing python module to deal with
data.  It has tons of features worthwhile learning, but the best of all is how
quick one can explore a data with just a few code lines once you learn the
basics.&lt;/p&gt;
&lt;p&gt;I wrote a small &lt;a href="http://code.google.com/p/python-oceans/source/browse/oceans/ctd/ctd.py#619"&gt;module&lt;/a&gt;
to read CTD (also XBT's EDF and FSI's CTD format) data directly as a pandas
DataFrame.  Here is an example how to use it:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[1:2] %}&lt;/p&gt;
&lt;p&gt;That's it the compressed &lt;a href="http://www.seabird.com/software/SBEDataProcforWindows.htm"&gt;SeaBird&lt;/a&gt; cnv file is loaded
into memory.&lt;/p&gt;
&lt;p&gt;If you have the Rossete file you can load and make a simple bottle summary with just two lines:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[2:3] %}&lt;/p&gt;
&lt;p&gt;Metadata and data flags are easily accessed.&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[3:4] %}&lt;/p&gt;
&lt;p&gt;Cleaning the DataFrame and manipulating the variables inside it is straight
forward:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[4:5] %}&lt;/p&gt;
&lt;p&gt;There are some rudimentary CTD processing steps similar to those found in the
SBE Software:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[6:11] %}&lt;/p&gt;
&lt;p&gt;This also allows for a more customize "derived" step:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[11:12] %}&lt;/p&gt;
&lt;p&gt;Last but not least a handy way for plotting the data:&lt;/p&gt;
&lt;p&gt;{% notebook CTD2DataFrame.ipynb cells[12:15] %}&lt;/p&gt;</summary><category term="CTD"></category><category term="pandas"></category></entry><entry><title>Dealing with spiky data</title><link href="http://ocefpaf.github.io/data.html" rel="alternate"></link><updated>2013-05-20T22:58:00Z</updated><author><name>Filipe Fernandes</name></author><id>tag:ocefpaf.github.io,2013-05-20:data.html</id><summary type="html">&lt;p&gt;The first steps to clean a data-set is to remove outliers (or spikes).  Some
spikes are easy to spot with a simple histogram of the data.  Let's take a look
at a velocity time-series with some bad data.&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[3:4] %}&lt;/p&gt;
&lt;p&gt;Can you see the bins that separate themselves from the rest?  Those are
probably spikes.  It is common practice to use a criteria of labeling the data
$3\times \sigma$ larger than the mean as outliers.  However, some spikes might
be "hidden" within the data limits, or one can remove good data together with
bad data if the data is highly variable (or episodic systems).  For a better
discussion on this topic check out Chapter 2 from Emery and Thomson -- Data
Analysis Methods in Physical Oceanography.&lt;/p&gt;
&lt;p&gt;One solution is a "two(or more)-pass" criteria.  Also, one might wish to
evaluate small chunks of the data separately.  Here is an example:&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[1:2] %}&lt;/p&gt;
&lt;p&gt;The first compute the statistics of the data ($\mu$ and $\sigma$) and marks
(but do not exclude yet) data that deviates more than $n1 \times \sigma$ from
the mean.  The second pass recompute the data statistics but now removing the
data that deviates more than $n2 \times \sigma$ from the mean.&lt;/p&gt;
&lt;p&gt;The code above makes use of &lt;a href="http://stackoverflow.com/questions/4936620/using-strides-for-an-efficient-moving-average-filter" title="NumPy stride tricks"&gt;NumPy stride tricks&lt;/a&gt;
to avoid loops while computing $\mu$ and $\sigma$ for each &lt;strong&gt;block&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;{% notebook spikey_data.ipynb cells[4:5] %}&lt;/p&gt;
&lt;p&gt;The "two-pass" method did well for &lt;em&gt;u&lt;/em&gt; while the $3\times \sigma$ criteria
failed not only to identify all the spikes, but also removed good data from the
time series.  On the other had, the $3\times \sigma$ criteria removed two bad
values from &lt;em&gt;v&lt;/em&gt; while the two pass could one find one.  Still both methods left
behind two small spikes on &lt;em&gt;v&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are probably better ways of doing this.  Also, there are methods that are
more statistically robust and more efficient at catching bad values.  Still,
the message of this post is not actually an algorithm to remove bad data, but:&lt;/p&gt;
&lt;p&gt;"To identify errors, it is necessary to examine all of the data in visual form
and to get a "feel" for the data."  -- directly from Emery and Thomson book.&lt;/p&gt;
&lt;p&gt;In other words, there is no silver bullet!&lt;/p&gt;
&lt;p&gt;http://www.johndcook.com/blog/2013/05/30/there-are-no-outliers/&lt;/p&gt;</summary><category term="plotting"></category><category term="spikes"></category></entry></feed>