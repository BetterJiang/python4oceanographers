{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "Iris (Python 2)",
   "language": "python",
   "name": "iris_python2"
  },
  "name": "",
  "signature": "sha256:f2da5a502b0b1cf3adecc758fa0be3d8d077b234d530b433f248793b2abf6244"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "\n",
      "with open('creative_commons.txt', 'r') as f:\n",
      "    html = f.read()\n",
      "    \n",
      "with open('./styles/custom.css', 'r') as f:\n",
      "    styles = f.read()\n",
      "    \n",
      "HTML(styles)\n",
      "\n",
      "name = '2014-09-29-exploring_cartopy'\n",
      "\n",
      "html = \"\"\"\n",
      "<small>\n",
      "<p> This post was written as an IPython notebook.  It is available for\n",
      "<a href=\"http://ocefpaf.github.com/python4oceanographers/downloads/\n",
      "notebooks/%s.ipynb\">download</a> or as a static\n",
      "<a href=\"http://nbviewer.ipython.org/url/ocefpaf.github.com/\n",
      "python4oceanographers/downloads/notebooks/%s.ipynb\">html</a>.</p>\n",
      "<p></p>\n",
      "%s \"\"\" % (name, name, html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import os\n",
      "from datetime import datetime\n",
      "\n",
      "title = \"Exploring what's new in Cartopy\"\n",
      "hour = datetime.utcnow().strftime('%H:%M')\n",
      "comments=\"true\"\n",
      "\n",
      "date = '-'.join(name.split('-')[:3])\n",
      "slug = '-'.join(name.split('-')[3:])\n",
      "\n",
      "metadata = dict(title=title,\n",
      "                date=date,\n",
      "                hour=hour,\n",
      "                comments=comments,\n",
      "                slug=slug,\n",
      "                name=name)\n",
      "\n",
      "markdown = \"\"\"Title: {title}\n",
      "date:  {date} {hour}\n",
      "comments: {comments}\n",
      "slug: {slug}\n",
      "\n",
      "{{% notebook {name}.ipynb cells[2:] %}}\n",
      "\"\"\".format(**metadata)\n",
      "\n",
      "content = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, '{}.md'.format(name)))\n",
      "with open('{}'.format(content), 'w') as f:\n",
      "    f.writelines(markdown)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://nbviewer.ipython.org/github/rjtavares/football-crunching/blob/master/notebooks/how%20to%20get%20full%20play-by-play%20data%20for%20the%20WC2014.ipynb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import json\n",
      "import requests\n",
      "import mechanize\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Initializes the browser.\n",
      "br = mechanize.Browser()\n",
      "br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=10)\n",
      "br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'http://data.huffingtonpost.com/2014/world-cup/matches/'\n",
      "match = 'brazil-vs-germany-731827'\n",
      "\n",
      "\n",
      "def get_match_data(match):\n",
      "    match_id = match.split('-')[-1]\n",
      "    response = mechanize.urlopen('http://data.huffingtonpost.com/2014/world-cup/matches/%s.json' % match_id)\n",
      "    return json.loads(response.read())    \n",
      "\n",
      "\n",
      "def get_match_names(match):\n",
      "    url = 'http://data.huffingtonpost.com/2014/world-cup/matches/%s' % match\n",
      "    response = mechanize.urlopen(url)\n",
      "    soup = BeautifulSoup(response)\n",
      "    data = {}\n",
      "    # Gets the second script block. Hopefully all pages follow the same format.\n",
      "    data_script = soup.findAll(\"script\")[1]\n",
      "    data_lines = data_script.text.split('\\n')\n",
      "    for line in data_lines[1:]:\n",
      "        if line:\n",
      "            # Format of a variable is HPIN.variable = [list of dictionaries].\n",
      "            # This tries to convert it to .\n",
      "            line_data = line.split(' = ')\n",
      "            name = line_data[0].split('.')[1]\n",
      "            value = json.loads(line_data[1][:-1])\n",
      "            data[name] = value\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pickle\n",
      "\n",
      "fname = \"./data/brazil_vs_germany_2014.pickle\"\n",
      "\n",
      "if os.path.isfile(fname):\n",
      "    pickle.load(open(fname, \"rb\"))\n",
      "else:\n",
      "    data = {}\n",
      "    match_data = get_match_data(match)\n",
      "    match_names = get_match_names(match)\n",
      "    data[match] = {'data': match_data, 'names': match_names}\n",
      "    \n",
      "    pickle.dump(data, open(fname, \"wb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "https://github.com/rjtavares/football-crunching/tree/master/notebooks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from footyviz import draw_events, draw_pitch, type_names\n",
      "\n",
      "pd.options.display.mpl_style = 'default'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(\"../datasets/germany-vs-argentina-731830.csv\", encoding='utf-8', index_col=0)\n",
      "\n",
      "#standard dimensions\n",
      "x_size = 105.0\n",
      "y_size = 68.0\n",
      "box_height = 16.5*2 + 7.32\n",
      "box_width = 16.5\n",
      "y_box_start = y_size/2-box_height/2\n",
      "y_box_end = y_size/2+box_height/2\n",
      "\n",
      "#scale of dataset is 100 by 100. Normalizing for a standard soccer pitch size\n",
      "df['x']=df['x']/100*x_size \n",
      "df['y']=df['y']/100*y_size\n",
      "df['to_x']=df['to_x']/100*x_size\n",
      "df['to_y']=df['to_y']/100*y_size\n",
      "\n",
      "#creating some measures and classifiers from the original \n",
      "df['count'] = 1\n",
      "df['dx'] = df['to_x'] - df['x']\n",
      "df['dy'] = df['to_y'] - df['y']\n",
      "df['distance'] = np.sqrt(df['dx']**2+df['dy']**2)\n",
      "df['fivemin'] = np.floor(df['min']/5)*5\n",
      "df['type_name'] = df['type'].map(type_names.get)\n",
      "df['to_box'] = (df['to_x'] > x_size - box_width) & (y_box_start < df['to_y']) & (df['to_y'] < y_box_end)\n",
      "df['from_box'] = (df['x'] > x_size - box_width) & (y_box_start < df['y']) & (df['y'] < y_box_end)\n",
      "df['on_offense'] = df['x']>x_size/2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}