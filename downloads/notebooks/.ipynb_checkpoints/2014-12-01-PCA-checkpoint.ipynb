{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "name": "",
  "signature": "sha256:5cb8ae0e49c0e0c5d0364004fbf19066e2049d2c14e78c4be5962ce44869221b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from IPython.core.display import HTML\n",
      "\n",
      "with open('creative_commons.txt', 'r') as f:\n",
      "    html = f.read()\n",
      "    \n",
      "with open('./styles/custom.css', 'r') as f:\n",
      "    styles = f.read()\n",
      "    \n",
      "HTML(styles)\n",
      "\n",
      "name = '2014-12-01-PCA'\n",
      "\n",
      "html = \"\"\"\n",
      "<small>\n",
      "<p> This post was written as an IPython notebook.  It is available for\n",
      "<a href=\"http://ocefpaf.github.com/python4oceanographers/downloads/\n",
      "notebooks/%s.ipynb\">download</a> or as a static\n",
      "<a href=\"http://nbviewer.ipython.org/url/ocefpaf.github.com/\n",
      "python4oceanographers/downloads/notebooks/%s.ipynb\">html</a>.</p>\n",
      "<p></p>\n",
      "%s \"\"\" % (name, name, html)\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "import seaborn\n",
      "from datetime import datetime\n",
      "\n",
      "title = \"Dissecando An\u00e1lise de Componentes Principais\"\n",
      "hour = datetime.utcnow().strftime('%H:%M')\n",
      "comments=\"true\"\n",
      "\n",
      "date = '-'.join(name.split('-')[:3])\n",
      "slug = '-'.join(name.split('-')[3:])\n",
      "\n",
      "metadata = dict(title=title,\n",
      "                date=date,\n",
      "                hour=hour,\n",
      "                comments=comments,\n",
      "                slug=slug,\n",
      "                name=name)\n",
      "\n",
      "markdown = \"\"\"Title: {title}\n",
      "date:  {date} {hour}\n",
      "comments: {comments}\n",
      "slug: {slug}\n",
      "\n",
      "{{% notebook {name}.ipynb cells[1:] %}}\n",
      "\"\"\".format(**metadata)\n",
      "\n",
      "content = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, '{}.md'.format(name)))\n",
      "with open('{}'.format(content), 'w') as f:\n",
      "    f.writelines(markdown)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Warning 1: This post is written in Portuguese.\n",
      "- Warning 2: Most of what I have here I got from other posts/examples online.  All links are provided and I encourage you to take a look at them.\n",
      "\n",
      "A An\u00e1lise de Componentes Principais (em ingl\u00eas\n",
      "[PCA](http://en.wikipedia.org/wiki/Principal_component_analysis)) \u00e9 o nome\n",
      "comum dado \u00e0 t\u00e9cnica que usa princ\u00edpios de \u00e1lgebra linear para transformar \n",
      "vari\u00e1veis, possivelmente correlacionadas, em um n\u00famero menor de vari\u00e1veis\n",
      "chamadas de Componentes Principais (novamente em ingl\u00eas PC).\n",
      "\n",
      "A PCA \u00e9 usada em diversas aplica\u00e7\u00f5es, desde a compress\u00e3o de dados (MP3,\n",
      "JPG) at\u00e9 remo\u00e7\u00e3o de ru\u00eddos, passando pela an\u00e1lises de grande quantidade de\n",
      "dados."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## PCA do ponto de vista da Geometria Espacial\n",
      "\n",
      "Em termos gerais a PCA busca reduzir o n\u00famero de dimens\u00f5es de um set de dados.\n",
      "Projetando os dados em um novo plano.  Usando essa nova proje\u00e7\u00e3o os dados\n",
      "originais, que podem envolver diversas vari\u00e1veis, podem ser interpretados\n",
      "utilizando menos \"dimens\u00f5es.\"\n",
      "\n",
      "No set de dados reduzido podemos observar com **mais clareza** tend\u00eancias,\n",
      "padr\u00f5es e/ou *outliers*.  Mas vale lembrar que a regra: \"Se n\u00e3o est\u00e1 nos dados\n",
      "brutos n\u00e3o existe!\" \u00e9 sempre v\u00e1lida.  A PCA fornece apenas mais clareza aos\n",
      "padr\u00f5es que j\u00e1 est\u00e3o l\u00e1.\n",
      "\n",
      "Utilizaremos dois vetores 1D conhecidos $(x, y)$ para entender essa nova\n",
      "proje\u00e7\u00e3o que a PCA faz.  Note que os vetores  possuem uma clara depend\u00eancia\n",
      "linear.\n",
      "\n",
      "O primeiro passo \u00e9 remover as **m\u00e9dias** dos dados.\n",
      "\n",
      "\n",
      "(Dados e exemplo:\n",
      "[http://bekoc.blogspot.com.br/2013/12/implementing-principle-component.html](http://bekoc.blogspot.com.br/2013/12/implementing-principle-component.html))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pandas import DataFrame\n",
      "\n",
      "x = np.array([2.5, 0.5, 2.2, 1.9, 3.1, 2.3, 2.0, 1.0, 1.5, 1.1])\n",
      "y = np.array([2.4, 0.7, 2.9, 2.2, 3.0, 2.7, 1.6, 1.1, 1.6, 0.9])\n",
      "\n",
      "Z = np.c_[x - x.mean(), y - y.mean()]\n",
      "df = DataFrame(Z, columns=['x', 'y'])\n",
      "df.index.name = 'Medidas'\n",
      "df.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>Medidas</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>x</th>\n",
        "      <td> 0.69</td>\n",
        "      <td>-1.31</td>\n",
        "      <td> 0.39</td>\n",
        "      <td> 0.09</td>\n",
        "      <td> 1.29</td>\n",
        "      <td> 0.49</td>\n",
        "      <td> 0.19</td>\n",
        "      <td>-0.81</td>\n",
        "      <td>-0.31</td>\n",
        "      <td>-0.71</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>y</th>\n",
        "      <td> 0.49</td>\n",
        "      <td>-1.21</td>\n",
        "      <td> 0.99</td>\n",
        "      <td> 0.29</td>\n",
        "      <td> 1.09</td>\n",
        "      <td> 0.79</td>\n",
        "      <td>-0.31</td>\n",
        "      <td>-0.81</td>\n",
        "      <td>-0.31</td>\n",
        "      <td>-1.01</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Medidas     0     1     2     3     4     5     6     7     8     9\n",
        "x        0.69 -1.31  0.39  0.09  1.29  0.49  0.19 -0.81 -0.31 -0.71\n",
        "y        0.49 -1.21  0.99  0.29  1.09  0.79 -0.31 -0.81 -0.31 -1.01"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O segundo passo \u00e9 a **normaliza\u00e7\u00e3o** dos dados.  A mais costumeira \u00e9,\n",
      "ap\u00f3s remover a m\u00e9dia, dividir os dados pelo desvio padr\u00e3o.  Esse procedimento \n",
      "tamb\u00e9m \u00e9 chamado de *z-score*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "line = dict(linewidth=1, linestyle='--', color='k')\n",
      "marker = dict(linestyle='none', marker='o', markersize=7, color='blue', alpha=0.5)\n",
      "\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(5, 5))\n",
      "ax.plot(x, y, **marker)\n",
      "ax.axhline(**line)\n",
      "ax.axvline(**line)\n",
      "ax.set_xlabel('x')\n",
      "ax.set_ylabel('y')\n",
      "ax.set_title(u'Dados Originais (com a m\u00e9dia)')\n",
      "_ = ax.axis([-1, 4, -1, 4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAFRCAYAAADnxm/tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF5dJREFUeJzt3X2UXVd53/Hv1ch26MyYxMmIKEXBJEFPWSRAGhNjm/DS\nFC/MW0AliYCQ2gQWIBIgsHg1WHJ4cQl1VqBYBChgygJUbARJoCUuwbjUIaShJE7c9CEYjESjIDmL\nYiOwsUanf5wzeDRsSSNr5uxz73w/a2np3plz737OvTO/u8/eZ58ZNU2DJOlI62oXIElDZDhKUoHh\nKEkFhqMkFRiOklRgOEpSwfraBax1EXEmcBNwQ/eldcCdwJsz830n+Fw/AuzPzBX50IuI9cDLgacB\nC+d8fRp4TWZ+4yiP+QLwiMy89RjP+07gg5n5qbtZ18eBl2Tm/zmBxzwYeEFmPvPutDkkEfFU4GXA\nwzPztsL3zwKuysz7RsRzgB/MzDce4/lmgA8BWzLz9tWqe9wYjsPw7cz82YU7EfHjwJ9GxMHM3F2x\nrl3A7cB5mfn/urD8beCzEXFWZn5r6QMW78fRZOazT6aozHzciWwfEeuA/wg84WTaHZA7gQtKwbhU\nZr59Gdt8KyI+CLwWeOkK1DcRDMcBysw9EXEJ7Q/q7ojYDFwBTAM/BvwV8KuZeUdEbAFeB3wb+Pzi\n54mI1wBbgUPAF4HfzMyvd4+5GDgMzAMvzczPLHnsOcDZwH0y83BX1yHgTRFxHvBc4N9HxB3AR4EH\nAU8H/ifwI8A3gTfRBtI3gb8A7p+Zj4qITwP/oav3T4GPd22dAVycmR+KiHsBbwc2AD8KfBX4lcw8\nEBE3A1u6fXoP8FPdvnweeE5mLl3Z8CvAlzNzX7dvm7vnnuse97quzQcAb+3qaIDLM/N9EfFI4DLg\n/wIP6F7r7cALgAA+nJkvXvo+RsTjgVcCp3b78d7MvKSw3c3A+4HHAT/cPfd5wM/RBuETM3NfRPzz\n7nX7ceCUiNiVmZd1z/E84EXda33joufeAfxwZv7Wceq5CnhjRLwpM/cvrXEtcsxxuG4Afqa7/Szg\nPZl5Lm0Q3Bd4bBcg76I9HDoL+PuFB0fERcBjgLMy80HA3wJXdt/+XeB5mfkQ4DXAIwrtnwv82UIw\nLvFJ4GHd7VOAP8rMf5GZi8P5WcC/pA2Tc4Cf4K5D82bR7fsCn8jMs2kP4X+3+/qvAtdn5rmZ+RO0\ngfSMRY8HeDIw0/VWH7Lo+ZZ6CvCxRfd3Af85M38aeCzw+oiYBf6IdjjjQcAFwBsi4qHdY84CXpuZ\n9we+Thsyj+328fkR8aOLG4yIEfBi4Ne71/kc4JURcUahvgY4LTMfDLwEeAfw+939vcCF3XbvA97d\nvddnA4+OiF/uhgy2A7+QmT8PHFz0Gi1+vY5aT3c4/T+6fRKG45A1tIEAbWj8U0S8FPgD2t7jDG1A\n/c2isbd3LHr8BbS/SN/p7r8F+MWIOIU2HD7ajf39EG0Pr9T+qUep7Qdoe1wLPrPk+yPaX7L3ZuZ3\nM/NO2p7aqPBcd2bmf+luf4G210ZmvgX484h4cUS8Dfhp2p7zYp8BHhAR1wKvoA2ULxfaCOBLAF0Y\nPJD2MJvM/Fpm3g/YRBtQH+2+vg/4MO0HTAN8JTP/unu+m4BPZeahzPwn4NaFuhd0vdcnAA/pjgIu\n7/Z/6T4s+HD3/5eBf8zMv1nU1g9FxD+j/RB7bTeu+1ng3rQ99n8F/MmiHt/S13rh9vHqual7rYTh\nOGQP4a5Jml3As4Gbgd8D/hfte3eYI38JDi26PVryvXV0wyiZ+Wraw7a/pO2VfLbr6Sx2PfDzEXGP\nQm2PAv5s0f3vG3ukPRxc/PNV6oECfHfR7Wah5oh4I3ApbS/t7cA1S/aHzLyZtid9GXA68MmI+DeF\nNg4DU93thdfoez2riLjfou8vNsVdQ093LPneIY4hIqZphz8eTHu4/1La16T0AbH0+e88Si0A52Tm\nz3a95XNp973hyNd6fsljmy5cj1fPVOGxa5bhOEDdmNiraT/dAc4Hficzr+run0373i30nB7Yff3C\nRU/zJ8BF3S8FtONj1wGHI+IrwHQ3WP984P4sGX/OzM91218ZET/Y1TUVERfTBtKxBvob2nHEX4uI\nU7uJnAs5ekCWnE/bE3w/cAB4NEcG2KgbZ3tPZl6Tma/o9vkBhef6IvCT3X7dShsOF3b7tIk26L8B\nfDcintx9/cdoxzX/G0cPtGO5HzBLO7P/ceCRwGmUQ/hYRsCom3z5c9rDbiLinrTv/xO7Gs/vxiTh\nyJ+DhedYTj0/CfzdCdY3sZyQGYZ7dIdK0AbI7cArMvO/dl97FfCRiPg6sIf2EOynMvOWiHga8P5u\nYuS/c1eP6F20h4p/0c3W/j3w9Mycj4gXAR+IiDu79i7qDn2X+jXacarrup7labQTKOcumildOvmx\ncP9K2kO0L9D2LL/CXcMEpe2X3v8d2gmfVwH7gatpQ3nxdu8FHhER/5t2nO2rwJsLbVxNOz55ZXf/\nacDOiPit7nl+IzO/FhFPAt7STWKsBy7NzOu6CZmj1Xk0f007zvl3EbGPtif+l90+fOU4j106Xrhw\n/2nAWyPiBtohjw9k5gcBIuJltGc43EY7+bV0fPeGY9UTEacBDwUuOk5ta8bIS5ZpNUTEo4ENXc+P\niHgz7SlLr6xQyzra3uLjMvMf+m5/HETEhbRnE7y8di1D0fthdURsiIi93aGjJteNwL+NiL+KiL+l\nPUXlDTUK6Wbcn12r/aHrZuqfCuyoXMqg9Npz7GZKP0Q7xvXEzPxib41L0gnou+f4JuBtwL6e25Wk\nE9JbOHZjGgcy85ruS3dnBlCSetHbYXVEXMddM2cPBhL4pcz8emn7pmma0Why83PHjh3s2LGjdhnS\nWrSsYKkyW92taHjOccYcmwMHjruufmxt2HA6+/cf9cI1Y29ubpZJfv/cv/E1Nze7rHD0JHBJKqhy\nEnhmPqpGu0Oyffv22iVIOgZ7jpU43igNm+EoSQWGoyQVGI6SVGA4SlKB4ViJEzLSsBmOlVx66aW1\nS5B0DIajJBUYjpJUYDhKUoHhKEkFhmMlrq2Whs1wrMRTeaRhMxwlqcBwlKQCw1GSCgxHSSowHCtx\nQkYaNsOxEtdWS8NmOEpSgeEoSQWGoyQVGI6SVGA4VuLaamnYDMdKPJVHGjbDUZIKDEdJKjAcJanA\ncJSkAsOxEidkpGEzHCtxbbU0bIajJBUYjpJUYDhKUoHhKEkFhmMlrq2Whs1wrMRTeaRhMxwlqcBw\nlKQCw1GSCgxHSSowHCtxQkYaNsOxEtdWS8NmOEpSgeEoSQWGoyQVGI6SVLC+z8YiYgp4J7AZaIDn\nZuaNfdYwFK6tloat757j44HDmfkw4NXA63tufzA8lUfjpGkamqapXUaveu05ZuYfRsTHurtnAt/o\ns31JJ6ZpGnbtmmLv3ikANm2aZ+vWeUajUeXKVl/vY46ZOR8RVwJvAT7Qd/uSlm/Xrin27JkCRsCI\nPXum2LlzPfv2TX4vssqETGZeSDvu+M6IuEeNGiQdW9M07N07dUQvcTQacfDgFLt3r5/4w+y+J2Se\nAdw7My8DvgMc7v4Vzc3N9lVaFe7feFsL+zc9DW2v8UgzM4eZmxtN9OF1r+EIXA1cGRHXAacAL8zM\nO4628YEDt/VWWN+uuOJynv/8l9QuY9XMzc1O9Pu33P1b6F2NW4jMzc1yyy3f4owz1rFnz129x6Zp\nmJk5zPnnH+KWW8ZrnxYs90NtNOCucTPJv1wbNpzO/v231i5j1az1cBz3iYyF/Wuahp0713PwYLsf\n09PzbNt2aGz2o2RubnZZxXsSuLQKJmUiYzQasWXLIaan55menmfLlvEOxhPR92G1NPGOPZHB2PW8\nNm4csW3bIWD8hgdOhuEo6bjWUigu8LBaWmGj0YhNm+aPONWlaZo1d1g67gzHSlxbPdm2bp1nZuau\ns9RmZg6zbdshNm40GMeF4ViJa6sn21qeyJgUjjlKq2StTmRMCsNRWkWG4vjysFqSCgxHqWdr8dqI\n48jD6kp27Ngx0Wur9f3GfUnhWmPPsRL/bvXaMylLCtcKw1HqwVq/NuI4MhwlqcBwlHrgksLxYzhK\nPXFJ4XgxHCtxbfXa45LC8eKVwCtZ61fKHncns3/j8KcTJvn9W+6VwD3PUerZkENRd/GwWpIKDEdJ\nKjAcJanAcKzEi91Kw2Y4VuLaamnYDEdJKjAcJanAcJQGzovj1uFJ4NJAeXHcuuw5VuLaah2PF8et\ny3CsxFN5dCxeHLc+w1GSCgxHaYC8OG59hqM0UF4cty7DURooL45bl+FYiRMyWo6NG0ds23bIHmMF\nhmMlrq3Wco1GI3uMFRiOklRgOEpH4bK9tc3lg9ISLtsT2HOUvo/L9gSGYzWurR4ml+1pgeFYiafy\nSMNmOEqLuGxPCwxHaQmX7QkMR+n7uGxP4Kk8UtHCsj3AYFyj7DlW4oTM8Llsb20zHCtxbbU0bL0e\nVkfEKcC7gfsApwGvy8w/7rMGSVqOvnuOTwcOZObDgccAb+25fUlalr4nZK4Cru5urwMO9dy+JC1L\nr+GYmQcBImKWNigv7rN9SVqu3k/liYhNwG7giszcdaxt5+Zm+ymqgu3bt0/0/sFkv3/g/k26UZ8L\n6SPiXsCngW2Zee1xNm8OHLht9YuqZG5uFvdvfLl/42tubnZZ52f13XN8FXBP4JKIuKT72gWZeXvP\ndUjSMfU95vhC4IV9tilJd4cngUtSgeEoSQWGYyWurZaGzXCsxLXV0rAZjpJUYDhKUoHhKEkFhqMk\nFRiOlfh3q6VhMxwr8VQeadgMR0kqMBwlqcBwlKQCw1GSCgzHSpyQkYbNcKzEtdUrp2ka+ryifd/t\nqY7e/4aMtFKapmHXrin27p0CYNOmebZunWc0WtZV8E+qvelpOOOMdavanuqy56ixtWvXFHv2TAEj\nYMSePVPs3LmefftWp1fXd3uqy3DUWGqahr17p47otY1GIw4enGL37vUrftjbd3uqz3CUpALDsRLX\nVp+c0WjEpk3zR/TYmqZhenqeLVsOrfg4YN/tqT7DsRJP5Tl5W7fOMzNz+Hv3Z2YOs23bITZuXJ2g\n6rs91XXccIyIh/RRiHSiRqMRW7YcYnp6vpce3OL2ZmYO22OccKPjDSRHxLXAHPBe4H2Z+Y99FAY0\nBw7c1lNT/Zubm8X9WxkLP8N9BVXTNMzNzXLLLd/qpb0aJvnnc25udlk/KMftOWbmo4DHAT8AXBMR\nH4uIp0TEKSdZo7QiRqNRrz24vttTHcsac8zMrwL/Cfgg8DPAC4AbI2LLKtYmSdUsZ8zx2RFxHfBJ\nYAo4LzMfDjwS+IPVLW9yOSEjDdtyeo6/AGwHNmfm6zLzawCZ+Q/AttUsbpK5tloatuOurc7MXz/G\n965e2XIkaRg8z1GSCgxHSSowHCWpwHCsxLXV0rAZjpV4Ko80bIajJBUYjpJUYDhKUoHhKEkFhmMl\nTshIw2Y4VuLaamnYDEdJKjAcJanAcJSkAsNRK65pGv/Ivcbeca/nqNUxiWurm6Zh164p9u6dYnoa\nzjhjHVu3zvv3VjSW7DlWMomn8uzaNcWePVPACBixZ88UO3euZ98+e5EaP4ajVkTTNOzdO3VEL3E0\nGnHw4BS7d6/3MFtjx3CUpIJq4RgRZ0fEtbXa18oajUZs2jR/RA+xaRqmp+fZsuWQ444aO1XCMSJe\nBrwTOK1G+1odW7fOMzNz+Hv3Z2YOs23bITZuNBg1fmr1HL8EbKEduV+TJnFCZjQasWXLIaan25C0\nx6hxNqo1UB4RZwIfzMxzjrJJc+DAbT1W1K8NG05n//5ba5exKpqmYW5ulltu+VbtUlbN3Nwsk/zz\nOcn7Nzc3u6xP7EGf5zg3N1u7hFXl/o0392+yDTocJ/WTa8Ek798k9zzA/Rtnyw392qfyePLbGuKy\nQo2Taj3HzLwZOLdW++rP4mWFAJs2zbusUINXu+e4Zk3i2uqjcVmhxpHhWMkknspT4rJCjSvDUZIK\nDEetKpcValwZjlp1LivUODIcteoWLyu0x6hxYThWslYmZBZs3Dhi27ZD9hg1NgzHStbi360ejUb2\nGDU2DEdJKjAc1wCX7UknbtAXntDJcdmedPfZc5xgLtuT7j7DsZLVXlvtsj3p5BiOlay1U3mkcWM4\nTiiX7Uknx3CcYC7bk+4+w3GCuWxPuvs8lWfCLSzbAwxG6QTYc6ykzwkZl+1JJ85wrGQtrq2Wxonh\nKEkFhqMkFRiOklRgOEpSgeFYyVr6u9XSODIcK3FttTRshqMkFRiOklRgOEpSgeEoSQWGYyVOyEjD\nZjhW4tpqadgMR0kqMBwlqcBwlKQCw1GSCgzHSlxbLQ2b4ViJp/JIw2Y4SlKB4ShJBYajJBUYjpJU\nYDhW4oSMNGyGYyWurZaGzXCUpALDUZIKDEdJKjAcJalgfZ+NRcQ6YCfwQOAO4FmZeVOfNQyFa6ul\nYeu75/gk4NTMPBd4BXB5z+0PhqfySMPWdzieB3wCIDM/B5zVc/uStCx9h+PpwK2L7s93h9qSNCxN\n0/T2b/PmzZdv3rz5lxfd33u0bbdv394A3/dv+/btTYnbu73bu/1ytm+WmVejpmnoS0RsAZ6QmRdF\nxEOB12Tm446yeXPgwG291da3ublZ3L/x5f6Nr7m52dFytuv7kPYjwO0RcT3tZMxv99z+YDghIw1b\nrz3HEzTRPccNG05n//5bj7/hmJrknge4f+NsqD1HSRoLhqMkFRiOklRgOEpSgeFYiWurpWEzHCvx\nVB5p2AxHSSowHCWpwHCUpALDUZIKDMdKnJCRhs1wrMS/Wy0Nm+EoSQWGoyQVGI6SVGA4SlKB4ViJ\na6ulYTMcK/FUHmnYDEdJKjAcJanAcJSkAsNRkgoMx0qckJGGzXCsxLXV0rAZjpJUYDhKUoHhKEkF\nhqMkFRiOlbi2Who2w7EST+WRhs1wlKQCw1GSCgxHSSowHCWpwHCsxAkZadgMx0pcWy0Nm+EoSQWG\noyQVGI6SVGA4SlKB4ViJa6ulYTMcK/FUHmnYDEdJKjAcJanAcJSkAsNRkgoMx0qckJGGzXCsxLXV\n0rBVCceIeHJEvL9G25K0HOv7bjAi3gycD3yh77Ylablq9ByvB54HjCq0LUnLsmo9x4j4DeBFS758\nYWZ+KCIeuVrtStJKGDVN03ujXTg+JzOf2nvjkrQMzlZLUkGtcGy6f5I0SFUOqyVp6DyslqQCw1GS\nCgxHSSrofYXM3RERTwaekplPr13LyYqIdcBO4IHAHcCzMvOmulWtvIg4G/h3mfmo2rWslIg4BXg3\ncB/gNOB1mfnHdataORExBbwT2Ew7YfrczLyxblUrLyI2AJ8HfjEzv3i07Qbfc+yWG76ByVlR8yTg\n1Mw8F3gFcHnlelZcRLyM9pfstNq1rLCnAwcy8+HAY4C3Vq5npT0eOJyZDwNeDby+cj0rrvuAeztw\n8HjbDj4cmbzlhucBnwDIzM8BZ9UtZ1V8CdjC5LxnC64CLulurwMOVaxlxWXmHwLP6e6eCXyjXjWr\n5k3A24B9x9twMIfVa2i54enArYvuz0fEusw8XKuglZaZuyPizNp1rLTMPAgQEbO0QXlx3YpWXmbO\nR8SVwJOBp1QuZ0VFxIW0Pf9rIuKVHOfDezDhmJnvAt5Vu44e3ArMLro/UcE46SJiE7AbuCIzd9Wu\nZzVk5oUR8XLgcxFx/8z8Tu2aVshFQBMR/xp4MPDeiPilzPx6aePBhOMacj3wBOCqiHgocEPlerRM\nEXEv4BpgW2ZeW7uelRYRzwDunZmXAd8BDnf/JkJmPmLhdkRcS3t9h2IwwviE4yQtN/wI8OiIuL67\nf1HNYlbZpLxnC14F3BO4JCIWxh4vyMzbK9a0kq4GroyI64BTgBdm5h2Va6rG5YOSVDAOs9WS1DvD\nUZIKDEdJKjAcJanAcJSkAsNRkgoMR0kqMBwlqcBw1NiKiBd0qzmIiIdFxBcjYrp2XZoMrpDRWIuI\nTwEfBn4TeGZmfrZySZoQ47K2WjqaZwI3Am81GLWSPKzWuDsT+Cbwc5Xr0IQxHDW2ImIGeAftJeC+\nHRHPq1ySJojhqHH2RuBjmfl52jHHSyLiPpVr0oRwQkaSCuw5SlKB4ShJBYajJBUYjpJUYDhKUoHh\nKEkFhqMkFRiOklTw/wHLCTlCrgJR2QAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f1551ad0bd0>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O terceiro passo \u00e9 calcular a **covari\u00e2ncia** dos dados normalizados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cov = np.cov(Z.T)\n",
      "cov"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([[ 0.61655556,  0.61544444],\n",
        "       [ 0.61544444,  0.71655556]])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A \"redu\u00e7\u00e3o\" dos dados pode ser feita por *Singular Value Decomposition*\n",
      "([SVD](http://en.wikipedia.org/wiki/Singular_value_decomposition))\n",
      "ou *Empirical Orthogonal Functions*\n",
      "([EOF](http://en.wikipedia.org/wiki/Empirical_orthogonal_functions)).\n",
      "Estamos buscando planos ortogonais entre as vari\u00e1veis que maximize a varian\u00e7a.\n",
      "\n",
      "Vamos utilizar a EOF, ou seja, calculando os `Autovalores` e `Autovetores`\n",
      "da matriz de covarian\u00e7a.  Mas colocarei aqui o correspondente usando a SVD como exerc\u00edcio:\n",
      "\n",
      "```python\n",
      "U, S, V = np.linalg.svd(cov, full_matrices=True, compute_uv=True)\n",
      "\n",
      "S  # Similar aos eigenvalues\n",
      "V  # Similar aos the eigenvectors\n",
      "PCs = np.dot(V, Z.T)  # Crie um gr\u00e1fico que se compare com os abaixo.\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvalues, eigenvectors = np.linalg.eig(cov)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvalues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([ 0.0490834 ,  1.28402771])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigenvectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[-0.73517866, -0.6778734 ],\n",
        "       [ 0.6778734 , -0.73517866]])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As **componentes principais** s\u00e3o os Autovetores.  \u00c9 comum normalizar os\n",
      "Autovetores para facilitar as compara\u00e7\u00f5es entre eles."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc = eigenvectors[1] / eigenvectors[0]\n",
      "pc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos plotar os **vetores** que definem esse novo plano ortogonal saindo do\n",
      "ponto $(0, 0)$ at\u00e9 $x$ m\u00e1ximo (Autovalor) e $y$ m\u00e1ximo (componente\n",
      "principal normalizada e dimensionada para o autovalor.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(5, 5))\n",
      "ax.plot(Z[:, 0], Z[:, 1], **marker)\n",
      "ax.set_xlim([-2, 2])\n",
      "ax.set_ylim([-2, 2])\n",
      "ax.axhline(**line)\n",
      "ax.axvline(**line)\n",
      "ax.set_xlabel('x')\n",
      "ax.set_ylabel('y')\n",
      "\n",
      "arrowprops = dict(width=0.01, head_width=0.05, alpha = 0.5,\n",
      "                  length_includes_head=False)\n",
      "a1 = ax.arrow(0, 0, eigenvalues[0], pc[0] * eigenvalues[0],\n",
      "              color='k', **arrowprops)\n",
      "a2 = ax.arrow(0, 0, eigenvalues[1], pc[1] * eigenvalues[1],\n",
      "              color='k', **arrowprops)\n",
      "a3 = ax.arrow(0, 0, -eigenvalues[0], -pc[0] * eigenvalues[0],\n",
      "              color='r', **arrowprops)\n",
      "a4 = ax.arrow(0, 0, -eigenvalues[1], -pc[1] * eigenvalues[1],\n",
      "              color='r', **arrowprops)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u00c9 f\u00e1cil de ver que esse novo plano se orienta onde os dados variam.  Bom,\n",
      "geometricamente e isso.  Agora vamos testar um pacote pronto para a an\u00e1lise de\n",
      "PCA.  Vou comparar o que acabamos de fazer com os resultados do m\u00f3dulo\n",
      "[scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "pca = PCA(n_components=2, copy=True)\n",
      "X = pca.fit_transform(Z)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(X[:, 0], X[:, 1], **marker) \n",
      "ax.set_xlim([-2, 2])\n",
      "ax.set_ylim([-2, 2])\n",
      "ax.axhline(**line)\n",
      "ax.axvline(**line)\n",
      "_ = ax.set_title(\"PCA\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Essa seria a cara dos dados \"rodados\" para o novo plano calculado pela an\u00e1lise.\n",
      "Para entender melhor o que isso quer dizer de uma olhada em:\n",
      "\n",
      "[https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/)\n",
      "\n",
      "Note que os dados em si s\u00e3o os mesmos.  Nos apenas rodamos para um novo set de\n",
      "eixos (principais).  Estamos literalmente olhado para os dados sob um novo\n",
      "\u00e2ngulo ;-).  Esse novo \"\u00e2ngulo\" \u00e9 mais intuitivo para tirarmos conclus\u00f5es sobre os\n",
      "dados.\n",
      "\n",
      "Um exemplo de aplica\u00e7\u00e3o direta em oceanografia f\u00edsica \u00e9 rodar as componentes\n",
      "da velocidade $u$ e $v$ de um fundeio em rio ou na plataforma continental para\n",
      "os seus eixos principais.  Intuitivamente podemos concluir que tais eixos, em\n",
      "geral, corresponder\u00e3o aos \"ao longo\" e \"perpendicular\" \u00e0 margem do rio ou d\u00e1\n",
      "is\u00f3bata do fundeio costeiro.  N\u00e3o \u00e9 mais intuitivo que eixos geogr\u00e1ficos Norte\n",
      "e Sul?\n",
      "\n",
      "([Aqui](https://github.com/ocefpaf/python-oceans/blob/master/oceans/ff_tools/ocfis.py#L354) tem uma fun\u00e7\u00e3o faz\n",
      "exatamente isso para s\u00e9ries temporais de velocidade.)\n",
      "\n",
      "Vamos comprar os resultados entre `sklearn` e o que fizemos anteriormente:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(eigenvectors)\n",
      "print('')\n",
      "print(pca.components_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mesmo resultado!  Mas note que as componentes est\u00e3o organizadas\n",
      "em ordem crescente dos autovalores no m\u00f3dulo `sklearn`.  O que\n",
      "mais temos no objeto `pca`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca.explained_variance_ratio_  # Quanto da vari\u00e2ncia \u00e9 explicada por cada componente."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para finalizar essa parte deixo\n",
      "[aqui](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)\n",
      "um exemplo 3D que compara outros m\u00f3dulos al\u00e9m do `sklearn`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Entendendo a PCA do ponto de visto estat\u00edstico\n",
      "\n",
      "Uma PCA entre duas vari\u00e1veis, como fizemos no exemplo acima, n\u00e3o \u00e9 muito\n",
      "diferente de uma correla\u00e7\u00e3o simples entre elas.  A PCA come\u00e7a a ser \u00fatil quando\n",
      "lidamos com diversas vari\u00e1veis.  Para entender essa afirma\u00e7\u00e3o vamos calcular a correla\u00e7\u00e3o de Pearson para os nossos dados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.stats import pearsonr\n",
      "\n",
      "r, p = pearsonr(x-x.mean(), y-y.mean())\n",
      "\n",
      "print('Pearson r: {}\\nPC 1: {}:'.format(r, pc[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bem pr\u00f3ximo da vari\u00e2ncia explicada pela primeira PC.  J\u00e1 que estamos tentado\n",
      "relacionar esse resultado com correla\u00e7\u00e3o linear simples,\n",
      "como seria a rela\u00e7\u00e3o entre a primeira Componente Principal e um ajuste linear?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.api as sm\n",
      "\n",
      "\n",
      "def OLSreg(y, Xmat):\n",
      "    return sm.OLS(y, sm.add_constant(Xmat, prepend=True)).fit()\n",
      "\n",
      "\n",
      "scale = lambda x: (x - x.mean()) / x.std()\n",
      "\n",
      "ols_fit = OLSreg(Z[:, 1], Z[:, 0])\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(5, 5))\n",
      "ax.plot(Z[:, 0], Z[:, 1], **marker)\n",
      "ax.set_xlim([-2, 2])\n",
      "ax.set_ylim([-2, 2])\n",
      "ax.axhline(**line)\n",
      "ax.axvline(**line)\n",
      "ax.set_xlabel('x')\n",
      "ax.set_xlabel('y')\n",
      "\n",
      "ax.plot(Z[:, 0], ols_fit.fittedvalues, 'r', alpha=0.5)\n",
      "ax.text(-1, 1, r'R$^2$ = %4.3f' % round(ols_fit.rsquared, 3))\n",
      "\n",
      "a1 = ax.arrow(0, 0, eigenvalues[1], pc[1] * eigenvalues[1],\n",
      "              **arrowprops)\n",
      "a2 = ax.arrow(0, 0, -eigenvalues[1], -pc[1] * eigenvalues[1],\n",
      "              **arrowprops)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "H\u00e1 um \u00e2ngulo pequeno entre as retas formadas pela correla\u00e7\u00e3o linear (vermelho)\n",
      "e a reta da **primeira** Componente Principal (azul).  Eu gosto de pensar que a\n",
      "correla\u00e7\u00e3o linear est\u00e1 \"contaminada\" pela vari\u00e2ncia da **segunda** Componente\n",
      "Principal."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# PCA com dados reais\n",
      "\n",
      "Usaremos dados de\n",
      "[consumo de comida](http://people.maths.ox.ac.uk/richardsonm/SignalProcPCA.pdf)\n",
      "em gramas, por pessoa, por semana, do Reino Unido."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file data.csv\n",
      "Food,England,Wales,Scotland,N Ireland\n",
      "Cheese,105,103,103,66\n",
      "Carcass meat,245,227,242,267\n",
      "Other meat,685,803,750,586\n",
      "Fish,147,160,122,93\n",
      "Fats and oils,193,235,184,209\n",
      "Sugars,156,175,147,139\n",
      "Fresh potatoes,720,874,566,1033\n",
      "Fresh Veg,253,265,171,143\n",
      "Other Veg,488,570,418,355\n",
      "Processed potatoes,198,203,220,187\n",
      "Processed Veg,360,365,337,334\n",
      "Fresh fruit,1102,1137,957,674\n",
      "Cereals,1472,1582,1462,1494\n",
      "Beverages,57,73,53,47\n",
      "Soft drinks,1374,1256,1572,1506\n",
      "Alcoholic drinks,375,475,458,135\n",
      "Confectionery,54,64,62,41"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "\n",
      "df = read_csv('data.csv', index_col='Food')\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sem realizar ajustes lineares para cada par de dados fica quase imposs\u00edvel\n",
      "visualizar algum padr\u00e3o ou tend\u00eancia nos dados acima.  Esse \u00e9 um caso onda a\n",
      "PCA pode ajudar.\n",
      "\n",
      "Vamos executar a PCA com o m\u00f3dulo `sklearn`.  Podemos usar `np.linalg.eig`\n",
      "(e calcular os autovalores e autovetores) ou `np.linalg.svd` ou qualquer outro\n",
      "m\u00f3dulo, desde que se conhe\u00e7a o que o m\u00f3dulo est\u00e1 calculando.\n",
      "\n",
      "(A prop\u00f3sito, o m\u00f3dulo `sklearn` usa *Singular Value Decomposition*.  Mas nos\n",
      " poupa do trabalho de ver como as sa\u00eddas `U`, `S` e `V` se relacionam com os\n",
      " autovetores e autovalores.)\n",
      "\n",
      "Come\u00e7aremos definindo uma fun\u00e7\u00e3o para normalizar os dados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "\n",
      "def z_score(x):\n",
      "    \"\"\"Remove a m\u00e9dia e normaliza os pelo desvio padr\u00e3o\"\"\"\n",
      "    return (x - x.mean()) / x.std()\n",
      "\n",
      "pca = PCA(n_components=None)\n",
      "pca.fit(df.apply(z_score).T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para facilitar vamos criar um um novo `DataFrame` com os resultados do objeto\n",
      "`pca`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "loadings = DataFrame(pca.components_.T)\n",
      "loadings.index = ['PC %s' % pc for pc in loadings.index + 1]\n",
      "loadings.columns = ['TS %s' % pc for pc in loadings.columns + 1]\n",
      "loadings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dependendo dos dados fica mais f\u00e1cil interpretar as componentes principais\n",
      "quando essas s\u00e3o projetadas nos dados originais.  Isso faz com que os n\u00fameros\n",
      "tenham o mesmo significado/unidades dos dados originais.\n",
      "\n",
      "Alguns *papers* n\u00e3o projetam!  Outros sim, tudo depende se os dados tem ou n\u00e3o\n",
      "a mesma unidade para fazer sentido (ou n\u00e3o)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PCs = np.dot(loadings.values.T, df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos ignorar a segunda dimens\u00e3o (PC 2) e plotar apenas a primeira, usando zero para a segunda."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "marker = dict(linestyle='none', marker='o', markersize=7, color='blue', alpha=0.5)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(7, 2.75))\n",
      "ax.plot(PCs[0], np.zeros_like(PCs[0]),\n",
      "        label=\"Scores\", **marker)\n",
      "[ax.text(x, y, t) for x, y, t in zip(PCs[0], loadings.values[1, :], df.columns)]\n",
      "\n",
      "ax.set_xlabel(\"PC1\")\n",
      "\n",
      "_ = ax.set_ylim(-1, 1)\n",
      "marker = dict(linestyle='none', marker='o', markersize=7, color='blue', alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Facilmente vemos que os habitantes da Irlanda do Norte t\u00eam uma dieta diferente\n",
      "da Inglaterra, Esc\u00f3cia e Pa\u00eds de Gales.  (O que seria uma boa hip\u00f3tese inicial,\n",
      "j\u00e1 que a Irlanda do Norte est\u00e1 geografica- e culturalmente mais afastada do\n",
      "resto do Reino Unido.  A prop\u00f3sito, muitas das hip\u00f3teses que vemos em *papers*\n",
      "s\u00e3o definidas assim, ap\u00f3s a an\u00e1lise ;-)\n",
      "\n",
      "Esse resultado n\u00e3o \u00e9 t\u00e3o evidente quando usamos uma correla\u00e7\u00e3o simples.  Note\n",
      "que a Irlanda do Norte se correlaciona menos com o resto, mas n\u00e3o t\u00e3o evidente\n",
      "como vemos na PC 1.  (Isso porque temos a\u00ed a \"contamina\u00e7\u00e3o\" da PC 2 nessa \n",
      "correla\u00e7\u00e3o, e nesse caso temos mais vari\u00e2ncia na PC 2 como veremos mais a\n",
      "frente.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax = seaborn.corrplot(df, annot=False, diag_names=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Agora vamos plotar a primeira e segunda dimens\u00f5es juntas.  Esse tipo de gr\u00e1fico\n",
      "\u00e9 chamado de *Score plot*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(7, 2.75))\n",
      "ax.plot(PCs[0], PCs[1], label=\"Scores\", **marker)\n",
      "\n",
      "ax.set_xlabel(\"PC1\")\n",
      "ax.set_ylabel(\"PC2\")\n",
      "\n",
      "text = [ax.text(x, y, t) for x, y, t in\n",
      "        zip(PCs[0], PCs[1]+0.5, df.columns)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fica claro que na \"segunda\" dimens\u00e3o est\u00e3o as diferen\u00e7as entre os tr\u00eas pa\u00edses\n",
      "que agrupamos no gr\u00e1fico anterior.\n",
      "\n",
      "Vamos criar mais alguns gr\u00e1ficos \u00fateis para ajudar na interpreta\u00e7\u00e3o\n",
      "dos dados.\n",
      "\n",
      "O quanto da vari\u00e2ncia dos dados \u00e9 explicada por cada componente?\n",
      "(Isso nos informa se estamos OK usando 1, 2 ou mais dimens\u00f5es.  Em\n",
      "geral se busca componentes o suficiente para explicar entre 70-80% dos dados.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perc = pca.explained_variance_ratio_ * 100\n",
      "\n",
      "perc = DataFrame(perc, columns=['Percentage explained ratio'], index=['PC %s' % pc for pc in np.arange(len(perc)) + 1])\n",
      "ax = perc.plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As componentes 1 e 2 juntas explicam mais de 96% da vari\u00e2ncia dos dados.  Nos\n",
      "sa\u00edmos de uma espa\u00e7o 17x4 para um espa\u00e7o de 2x4!  (Se isso fosse a compress\u00e3o\n",
      "de uma foto para um arquivo JPEG nos ter\u00edamos um arquivo bem reduzido.)\n",
      "\n",
      "Vamos olhar tamb\u00e9m a \"s\u00e9rie\" para a primeira componente."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TS1 = loadings['TS 1']\n",
      "TS1.index = df.index\n",
      "ax = TS1.plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note que *Fresh Potatoes* \u00e9 o inverso de *Fresh Fruit*, certo?  Checando os\n",
      "dados originais vemos que a Irlanda do Norte consome mais *Fresh Potatoes* e\n",
      "menos *Fresh Fruit* que o resto do Reino Unido.  Esse n\u00e3o foi o resultado mais \n",
      "not\u00e1vel da primeira componente?  As coisas come\u00e7am a se encaixar!\n",
      "\n",
      "Outro gr\u00e1fico comum para explorar os resultados \u00e9 o *Loadings plot* ou seja, a\n",
      "influ\u00eancia de cada vari\u00e1vel original nas componentes principais.  Note que\n",
      "*Fresh Fruit*, *Alcoholic drinks*, *Soft drinks* e *Fresh potatoes* se destacam\n",
      "da aglomera\u00e7\u00e3o central.  Olhe novamente a tabela de dados e veja se enxerga\n",
      "algum padr\u00e3o entre os pa\u00edses e essas comidas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "marker = dict(linestyle='none', marker='o', markersize=7, color='blue', alpha=0.5)\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(7, 7))\n",
      "ax.plot(loadings.icol(0), loadings.icol(1), label=\"Loadings\", **marker)\n",
      "ax.set_xlabel(\"non-projected PC1\")\n",
      "ax.set_ylabel(\"non-projected PC2\")\n",
      "ax.axis([-1, 1, -1, 1])\n",
      "text = [ax.text(x, y, t) for\n",
      "        x, y, t in zip(loadings.icol(0), loadings.icol(1), df.index)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Agora podemos retornar aos dados originais e, de posse desse conhecimento,\n",
      "come\u00e7ar e discutir os dados."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}